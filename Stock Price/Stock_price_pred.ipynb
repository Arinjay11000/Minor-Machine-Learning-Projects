{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stock price pred.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM8jMy9YBlhnpTedDGV1iRF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arinjay11000/Minor-Machine-Learning-Projects/blob/main/Stock%20Price/Stock_price_pred.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aJtXyj3qtgs7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas_datareader as pdr\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "oJNhlUawA7Kt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pandas\n",
        "!pip install --upgrade pandas-datareader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "H3f4NA8HCvoZ",
        "outputId": "c9c333f6-b62c-428b-e714-af9ef29f9829"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: pandas-datareader in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Collecting pandas-datareader\n",
            "  Downloading pandas_datareader-0.10.0-py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader) (2.23.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pandas-datareader) (4.2.6)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->pandas-datareader) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->pandas-datareader) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->pandas-datareader) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23->pandas-datareader) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader) (2021.10.8)\n",
            "Installing collected packages: pandas-datareader\n",
            "  Attempting uninstall: pandas-datareader\n",
            "    Found existing installation: pandas-datareader 0.9.0\n",
            "    Uninstalling pandas-datareader-0.9.0:\n",
            "      Successfully uninstalled pandas-datareader-0.9.0\n",
            "Successfully installed pandas-datareader-0.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas_datareader"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "key=\"7993cb7a9720eec8af4a1bdf0e5459453553dbdb\"\n",
        "df = pdr.get_data_tiingo('AAPL', api_key=key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jcIcE_3ugQJ",
        "outputId": "335daaa2-8aa4-4eb8-d3e4-1537cdd0d58e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas_datareader/tiingo.py:234: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
            "  return pd.concat(dfs, self._concat_axis)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "TQbygLNkc9yI",
        "outputId": "419b9ec1-64e8-4f50-c001-25c5738181d7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   close    high     low    open    volume  \\\n",
              "symbol date                                                                  \n",
              "AAPL   2017-05-01 00:00:00+00:00  146.58  147.20  144.96  145.10  32818760   \n",
              "       2017-05-02 00:00:00+00:00  147.51  148.09  146.84  147.54  39752670   \n",
              "       2017-05-03 00:00:00+00:00  147.06  147.49  144.27  145.59  45142806   \n",
              "       2017-05-04 00:00:00+00:00  146.53  147.14  145.81  146.52  23275690   \n",
              "       2017-05-05 00:00:00+00:00  148.96  148.98  146.76  146.76  26787359   \n",
              "\n",
              "                                   adjClose    adjHigh     adjLow    adjOpen  \\\n",
              "symbol date                                                                    \n",
              "AAPL   2017-05-01 00:00:00+00:00  34.593441  34.739763  34.211115  34.244155   \n",
              "       2017-05-02 00:00:00+00:00  34.812924  34.949807  34.654802  34.820004   \n",
              "       2017-05-03 00:00:00+00:00  34.706723  34.808204  34.048272  34.359797   \n",
              "       2017-05-04 00:00:00+00:00  34.581641  34.725603  34.411718  34.579281   \n",
              "       2017-05-05 00:00:00+00:00  35.155130  35.159850  34.635922  34.635922   \n",
              "\n",
              "                                  adjVolume  divCash  splitFactor  \n",
              "symbol date                                                        \n",
              "AAPL   2017-05-01 00:00:00+00:00  131275040      0.0          1.0  \n",
              "       2017-05-02 00:00:00+00:00  159010680      0.0          1.0  \n",
              "       2017-05-03 00:00:00+00:00  180571224      0.0          1.0  \n",
              "       2017-05-04 00:00:00+00:00   93102760      0.0          1.0  \n",
              "       2017-05-05 00:00:00+00:00  107149436      0.0          1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-beb7ddce-fda3-4df7-bed2-7cafa70d34c6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>close</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>open</th>\n",
              "      <th>volume</th>\n",
              "      <th>adjClose</th>\n",
              "      <th>adjHigh</th>\n",
              "      <th>adjLow</th>\n",
              "      <th>adjOpen</th>\n",
              "      <th>adjVolume</th>\n",
              "      <th>divCash</th>\n",
              "      <th>splitFactor</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>symbol</th>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">AAPL</th>\n",
              "      <th>2017-05-01 00:00:00+00:00</th>\n",
              "      <td>146.58</td>\n",
              "      <td>147.20</td>\n",
              "      <td>144.96</td>\n",
              "      <td>145.10</td>\n",
              "      <td>32818760</td>\n",
              "      <td>34.593441</td>\n",
              "      <td>34.739763</td>\n",
              "      <td>34.211115</td>\n",
              "      <td>34.244155</td>\n",
              "      <td>131275040</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-05-02 00:00:00+00:00</th>\n",
              "      <td>147.51</td>\n",
              "      <td>148.09</td>\n",
              "      <td>146.84</td>\n",
              "      <td>147.54</td>\n",
              "      <td>39752670</td>\n",
              "      <td>34.812924</td>\n",
              "      <td>34.949807</td>\n",
              "      <td>34.654802</td>\n",
              "      <td>34.820004</td>\n",
              "      <td>159010680</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-05-03 00:00:00+00:00</th>\n",
              "      <td>147.06</td>\n",
              "      <td>147.49</td>\n",
              "      <td>144.27</td>\n",
              "      <td>145.59</td>\n",
              "      <td>45142806</td>\n",
              "      <td>34.706723</td>\n",
              "      <td>34.808204</td>\n",
              "      <td>34.048272</td>\n",
              "      <td>34.359797</td>\n",
              "      <td>180571224</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-05-04 00:00:00+00:00</th>\n",
              "      <td>146.53</td>\n",
              "      <td>147.14</td>\n",
              "      <td>145.81</td>\n",
              "      <td>146.52</td>\n",
              "      <td>23275690</td>\n",
              "      <td>34.581641</td>\n",
              "      <td>34.725603</td>\n",
              "      <td>34.411718</td>\n",
              "      <td>34.579281</td>\n",
              "      <td>93102760</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-05-05 00:00:00+00:00</th>\n",
              "      <td>148.96</td>\n",
              "      <td>148.98</td>\n",
              "      <td>146.76</td>\n",
              "      <td>146.76</td>\n",
              "      <td>26787359</td>\n",
              "      <td>35.155130</td>\n",
              "      <td>35.159850</td>\n",
              "      <td>34.635922</td>\n",
              "      <td>34.635922</td>\n",
              "      <td>107149436</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-beb7ddce-fda3-4df7-bed2-7cafa70d34c6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-beb7ddce-fda3-4df7-bed2-7cafa70d34c6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-beb7ddce-fda3-4df7-bed2-7cafa70d34c6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"AAPL.csv\")"
      ],
      "metadata": {
        "id": "PjD9gntVwzaL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option(\"display.max_columns\",500)"
      ],
      "metadata": {
        "id": "zxR_6T9wJU0F"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/AAPL.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "f9gBPqwvI2wO",
        "outputId": "5b3bdb5e-2d55-4f6f-d0ac-4b641e8f7500"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  symbol                       date   close    high     low    open    volume  \\\n",
              "0   AAPL  2017-05-01 00:00:00+00:00  146.58  147.20  144.96  145.10  32818760   \n",
              "1   AAPL  2017-05-02 00:00:00+00:00  147.51  148.09  146.84  147.54  39752670   \n",
              "2   AAPL  2017-05-03 00:00:00+00:00  147.06  147.49  144.27  145.59  45142806   \n",
              "3   AAPL  2017-05-04 00:00:00+00:00  146.53  147.14  145.81  146.52  23275690   \n",
              "4   AAPL  2017-05-05 00:00:00+00:00  148.96  148.98  146.76  146.76  26787359   \n",
              "\n",
              "    adjClose    adjHigh     adjLow    adjOpen  adjVolume  divCash  splitFactor  \n",
              "0  34.593441  34.739763  34.211115  34.244155  131275040      0.0          1.0  \n",
              "1  34.812924  34.949807  34.654802  34.820004  159010680      0.0          1.0  \n",
              "2  34.706723  34.808204  34.048272  34.359797  180571224      0.0          1.0  \n",
              "3  34.581641  34.725603  34.411718  34.579281   93102760      0.0          1.0  \n",
              "4  35.155130  35.159850  34.635922  34.635922  107149436      0.0          1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ca8a65d9-4a47-48fd-9ad5-867f9afdb2ce\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>symbol</th>\n",
              "      <th>date</th>\n",
              "      <th>close</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>open</th>\n",
              "      <th>volume</th>\n",
              "      <th>adjClose</th>\n",
              "      <th>adjHigh</th>\n",
              "      <th>adjLow</th>\n",
              "      <th>adjOpen</th>\n",
              "      <th>adjVolume</th>\n",
              "      <th>divCash</th>\n",
              "      <th>splitFactor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>2017-05-01 00:00:00+00:00</td>\n",
              "      <td>146.58</td>\n",
              "      <td>147.20</td>\n",
              "      <td>144.96</td>\n",
              "      <td>145.10</td>\n",
              "      <td>32818760</td>\n",
              "      <td>34.593441</td>\n",
              "      <td>34.739763</td>\n",
              "      <td>34.211115</td>\n",
              "      <td>34.244155</td>\n",
              "      <td>131275040</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>2017-05-02 00:00:00+00:00</td>\n",
              "      <td>147.51</td>\n",
              "      <td>148.09</td>\n",
              "      <td>146.84</td>\n",
              "      <td>147.54</td>\n",
              "      <td>39752670</td>\n",
              "      <td>34.812924</td>\n",
              "      <td>34.949807</td>\n",
              "      <td>34.654802</td>\n",
              "      <td>34.820004</td>\n",
              "      <td>159010680</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>2017-05-03 00:00:00+00:00</td>\n",
              "      <td>147.06</td>\n",
              "      <td>147.49</td>\n",
              "      <td>144.27</td>\n",
              "      <td>145.59</td>\n",
              "      <td>45142806</td>\n",
              "      <td>34.706723</td>\n",
              "      <td>34.808204</td>\n",
              "      <td>34.048272</td>\n",
              "      <td>34.359797</td>\n",
              "      <td>180571224</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>2017-05-04 00:00:00+00:00</td>\n",
              "      <td>146.53</td>\n",
              "      <td>147.14</td>\n",
              "      <td>145.81</td>\n",
              "      <td>146.52</td>\n",
              "      <td>23275690</td>\n",
              "      <td>34.581641</td>\n",
              "      <td>34.725603</td>\n",
              "      <td>34.411718</td>\n",
              "      <td>34.579281</td>\n",
              "      <td>93102760</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>2017-05-05 00:00:00+00:00</td>\n",
              "      <td>148.96</td>\n",
              "      <td>148.98</td>\n",
              "      <td>146.76</td>\n",
              "      <td>146.76</td>\n",
              "      <td>26787359</td>\n",
              "      <td>35.155130</td>\n",
              "      <td>35.159850</td>\n",
              "      <td>34.635922</td>\n",
              "      <td>34.635922</td>\n",
              "      <td>107149436</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca8a65d9-4a47-48fd-9ad5-867f9afdb2ce')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ca8a65d9-4a47-48fd-9ad5-867f9afdb2ce button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ca8a65d9-4a47-48fd-9ad5-867f9afdb2ce');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tANq951fJNga",
        "outputId": "b522fec8-39bf-4c60-82d4-ef48adc0ef2e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1260 entries, 0 to 1259\n",
            "Data columns (total 14 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   symbol       1260 non-null   object \n",
            " 1   date         1260 non-null   object \n",
            " 2   close        1260 non-null   float64\n",
            " 3   high         1260 non-null   float64\n",
            " 4   low          1260 non-null   float64\n",
            " 5   open         1260 non-null   float64\n",
            " 6   volume       1260 non-null   int64  \n",
            " 7   adjClose     1260 non-null   float64\n",
            " 8   adjHigh      1260 non-null   float64\n",
            " 9   adjLow       1260 non-null   float64\n",
            " 10  adjOpen      1260 non-null   float64\n",
            " 11  adjVolume    1260 non-null   int64  \n",
            " 12  divCash      1260 non-null   float64\n",
            " 13  splitFactor  1260 non-null   float64\n",
            "dtypes: float64(10), int64(2), object(2)\n",
            "memory usage: 137.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "v45ZJfHcJRtl",
        "outputId": "5cca5e54-c696-4774-c1ca-2222d3e2c6a5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     symbol                       date   close     high     low    open  \\\n",
              "1255   AAPL  2022-04-25 00:00:00+00:00  162.88  163.170  158.46  161.12   \n",
              "1256   AAPL  2022-04-26 00:00:00+00:00  156.80  162.340  156.72  162.25   \n",
              "1257   AAPL  2022-04-27 00:00:00+00:00  156.57  159.790  155.38  155.91   \n",
              "1258   AAPL  2022-04-28 00:00:00+00:00  163.64  164.515  158.93  159.25   \n",
              "1259   AAPL  2022-04-29 00:00:00+00:00  157.65  166.200  157.25  161.84   \n",
              "\n",
              "         volume  adjClose  adjHigh  adjLow  adjOpen  adjVolume  divCash  \\\n",
              "1255   96046376    162.88  163.170  158.46   161.12   96046376      0.0   \n",
              "1256   94008394    156.80  162.340  156.72   162.25   94008394      0.0   \n",
              "1257   88063191    156.57  159.790  155.38   155.91   88063191      0.0   \n",
              "1258  130216792    163.64  164.515  158.93   159.25  130216792      0.0   \n",
              "1259  131747571    157.65  166.200  157.25   161.84  131747571      0.0   \n",
              "\n",
              "      splitFactor  \n",
              "1255          1.0  \n",
              "1256          1.0  \n",
              "1257          1.0  \n",
              "1258          1.0  \n",
              "1259          1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-049fe439-073c-4147-8c45-4f3ecc569fb7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>symbol</th>\n",
              "      <th>date</th>\n",
              "      <th>close</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>open</th>\n",
              "      <th>volume</th>\n",
              "      <th>adjClose</th>\n",
              "      <th>adjHigh</th>\n",
              "      <th>adjLow</th>\n",
              "      <th>adjOpen</th>\n",
              "      <th>adjVolume</th>\n",
              "      <th>divCash</th>\n",
              "      <th>splitFactor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1255</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>2022-04-25 00:00:00+00:00</td>\n",
              "      <td>162.88</td>\n",
              "      <td>163.170</td>\n",
              "      <td>158.46</td>\n",
              "      <td>161.12</td>\n",
              "      <td>96046376</td>\n",
              "      <td>162.88</td>\n",
              "      <td>163.170</td>\n",
              "      <td>158.46</td>\n",
              "      <td>161.12</td>\n",
              "      <td>96046376</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1256</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>2022-04-26 00:00:00+00:00</td>\n",
              "      <td>156.80</td>\n",
              "      <td>162.340</td>\n",
              "      <td>156.72</td>\n",
              "      <td>162.25</td>\n",
              "      <td>94008394</td>\n",
              "      <td>156.80</td>\n",
              "      <td>162.340</td>\n",
              "      <td>156.72</td>\n",
              "      <td>162.25</td>\n",
              "      <td>94008394</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1257</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>2022-04-27 00:00:00+00:00</td>\n",
              "      <td>156.57</td>\n",
              "      <td>159.790</td>\n",
              "      <td>155.38</td>\n",
              "      <td>155.91</td>\n",
              "      <td>88063191</td>\n",
              "      <td>156.57</td>\n",
              "      <td>159.790</td>\n",
              "      <td>155.38</td>\n",
              "      <td>155.91</td>\n",
              "      <td>88063191</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1258</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>2022-04-28 00:00:00+00:00</td>\n",
              "      <td>163.64</td>\n",
              "      <td>164.515</td>\n",
              "      <td>158.93</td>\n",
              "      <td>159.25</td>\n",
              "      <td>130216792</td>\n",
              "      <td>163.64</td>\n",
              "      <td>164.515</td>\n",
              "      <td>158.93</td>\n",
              "      <td>159.25</td>\n",
              "      <td>130216792</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1259</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>2022-04-29 00:00:00+00:00</td>\n",
              "      <td>157.65</td>\n",
              "      <td>166.200</td>\n",
              "      <td>157.25</td>\n",
              "      <td>161.84</td>\n",
              "      <td>131747571</td>\n",
              "      <td>157.65</td>\n",
              "      <td>166.200</td>\n",
              "      <td>157.25</td>\n",
              "      <td>161.84</td>\n",
              "      <td>131747571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-049fe439-073c-4147-8c45-4f3ecc569fb7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-049fe439-073c-4147-8c45-4f3ecc569fb7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-049fe439-073c-4147-8c45-4f3ecc569fb7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1=df.reset_index()['close']\n",
        "df1.head()"
      ],
      "metadata": {
        "id": "cX_Xm5wTKazl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fb5e4f0-481f-427d-e55e-a0744c1ff071"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    146.58\n",
              "1    147.51\n",
              "2    147.06\n",
              "3    146.53\n",
              "4    148.96\n",
              "Name: close, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(df1)"
      ],
      "metadata": {
        "id": "gIMraRi9dUTr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "361008fd-c040-4d02-d7b2-d0afec486263"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7cefb92a90>]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler=MinMaxScaler(feature_range=(0,1))\n",
        "df1=scaler.fit_transform(np.array(df1).reshape(-1,1))"
      ],
      "metadata": {
        "id": "CyeU_V0ifgEI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6XK0rHsftWQ",
        "outputId": "c8b89229-6b9a-4953-8bbc-ffcb27a76537"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.09953663]\n",
            " [0.101866  ]\n",
            " [0.10073889]\n",
            " ...\n",
            " [0.12455855]\n",
            " [0.14226675]\n",
            " [0.12726362]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_size=int(len(df1)*0.8)\n",
        "test_size=len(df1)-training_size\n",
        "train_data,test_data=df1[0:training_size,:],df1[training_size:len(df1),:1]"
      ],
      "metadata": {
        "id": "-7lq-thCfvN2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_size,test_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaBqDb6gjgXs",
        "outputId": "d1aa471f-f43a-4525-dc23-35dceabed111"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1008, 252)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(dataset, time_step=1):\n",
        "\tdataX, dataY = [], []\n",
        "\tfor i in range(len(dataset)-time_step-1):\n",
        "\t\ta = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n",
        "\t\tdataX.append(a)\n",
        "\t\tdataY.append(dataset[i + time_step, 0])\n",
        "\treturn np.array(dataX), np.array(dataY)"
      ],
      "metadata": {
        "id": "zLkoFgpMjk9d"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_step = 100\n",
        "X_train, y_train = create_dataset(train_data, time_step)\n",
        "X_test, ytest = create_dataset(test_data, time_step)"
      ],
      "metadata": {
        "id": "Mc9gDHrcjxJE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape), print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLJsRWbXkKle",
        "outputId": "375c641c-223f-42e5-e706-76db1acb0725"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(907, 100)\n",
            "(907,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test.shape), print(ytest.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWRf6WozkPSP",
        "outputId": "72d9c597-5c22-46ed-e2f0-54240866c59f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(151, 100)\n",
            "(151,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape input to be [samples, time steps, features] which is required for LSTM\n",
        "X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n",
        "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)"
      ],
      "metadata": {
        "id": "oDDG9d2qkUd8"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(LSTM(50,return_sequences=True,input_shape=(100,1)))\n",
        "model.add(LSTM(50,return_sequences=True))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error',optimizer='adam')"
      ],
      "metadata": {
        "id": "rlN53ikKkaFz"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpfeQujRkg3s",
        "outputId": "b6dc7e06-1526-45ce-b41d-3e5a8aa210dc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 100, 50)           10400     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100, 50)           20200     \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 50)                20200     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50,851\n",
            "Trainable params: 50,851\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from datetime import datetime \n",
        "\n",
        "num_epochs = 100\n",
        "num_batch_size = 32\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='saved_models/Stock.hdf5', \n",
        "                               verbose=1, save_best_only=True)\n",
        "start = datetime.now()\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, ytest), callbacks=[checkpointer], verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpaR0Y8xk7xG",
        "outputId": "0cbe88f5-2bea-4fa9-afe2-b217f9a2b27e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0258\n",
            "Epoch 1: val_loss improved from inf to 0.00203, saving model to saved_models/Stock.hdf5\n",
            "29/29 [==============================] - 21s 423ms/step - loss: 0.0258 - val_loss: 0.0020\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0089\n",
            "Epoch 2: val_loss improved from 0.00203 to 0.00063, saving model to saved_models/Stock.hdf5\n",
            "29/29 [==============================] - 9s 303ms/step - loss: 0.0089 - val_loss: 6.3007e-04\n",
            "Epoch 3/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0072\n",
            "Epoch 3: val_loss did not improve from 0.00063\n",
            "29/29 [==============================] - 5s 157ms/step - loss: 0.0072 - val_loss: 0.0011\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0073\n",
            "Epoch 4: val_loss improved from 0.00063 to 0.00033, saving model to saved_models/Stock.hdf5\n",
            "29/29 [==============================] - 5s 156ms/step - loss: 0.0073 - val_loss: 3.3352e-04\n",
            "Epoch 5/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0052\n",
            "Epoch 5: val_loss improved from 0.00033 to 0.00029, saving model to saved_models/Stock.hdf5\n",
            "29/29 [==============================] - 4s 153ms/step - loss: 0.0052 - val_loss: 2.8682e-04\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0047\n",
            "Epoch 6: val_loss did not improve from 0.00029\n",
            "29/29 [==============================] - 4s 154ms/step - loss: 0.0047 - val_loss: 3.9541e-04\n",
            "Epoch 7/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0043\n",
            "Epoch 7: val_loss did not improve from 0.00029\n",
            "29/29 [==============================] - 4s 152ms/step - loss: 0.0043 - val_loss: 5.3266e-04\n",
            "Epoch 8/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0039\n",
            "Epoch 8: val_loss did not improve from 0.00029\n",
            "29/29 [==============================] - 4s 151ms/step - loss: 0.0039 - val_loss: 4.9714e-04\n",
            "Epoch 9/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0032\n",
            "Epoch 9: val_loss did not improve from 0.00029\n",
            "29/29 [==============================] - 4s 152ms/step - loss: 0.0032 - val_loss: 5.0942e-04\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0037\n",
            "Epoch 10: val_loss improved from 0.00029 to 0.00024, saving model to saved_models/Stock.hdf5\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 0.0037 - val_loss: 2.4416e-04\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0027\n",
            "Epoch 11: val_loss did not improve from 0.00024\n",
            "29/29 [==============================] - 4s 152ms/step - loss: 0.0027 - val_loss: 4.6147e-04\n",
            "Epoch 12/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0025\n",
            "Epoch 12: val_loss did not improve from 0.00024\n",
            "29/29 [==============================] - 4s 153ms/step - loss: 0.0025 - val_loss: 3.9097e-04\n",
            "Epoch 13/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0026\n",
            "Epoch 13: val_loss improved from 0.00024 to 0.00020, saving model to saved_models/Stock.hdf5\n",
            "29/29 [==============================] - 4s 154ms/step - loss: 0.0026 - val_loss: 1.9817e-04\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0024\n",
            "Epoch 14: val_loss did not improve from 0.00020\n",
            "29/29 [==============================] - 5s 155ms/step - loss: 0.0024 - val_loss: 3.9456e-04\n",
            "Epoch 15/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0026\n",
            "Epoch 15: val_loss did not improve from 0.00020\n",
            "29/29 [==============================] - 5s 157ms/step - loss: 0.0026 - val_loss: 3.5151e-04\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0024\n",
            "Epoch 16: val_loss did not improve from 0.00020\n",
            "29/29 [==============================] - 5s 155ms/step - loss: 0.0024 - val_loss: 2.3184e-04\n",
            "Epoch 17/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0020\n",
            "Epoch 17: val_loss did not improve from 0.00020\n",
            "29/29 [==============================] - 5s 156ms/step - loss: 0.0020 - val_loss: 4.9594e-04\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0022\n",
            "Epoch 18: val_loss did not improve from 0.00020\n",
            "29/29 [==============================] - 5s 157ms/step - loss: 0.0022 - val_loss: 2.6580e-04\n",
            "Epoch 19/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0022\n",
            "Epoch 19: val_loss did not improve from 0.00020\n",
            "29/29 [==============================] - 5s 158ms/step - loss: 0.0022 - val_loss: 2.4374e-04\n",
            "Epoch 20/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0023\n",
            "Epoch 20: val_loss improved from 0.00020 to 0.00019, saving model to saved_models/Stock.hdf5\n",
            "29/29 [==============================] - 5s 155ms/step - loss: 0.0023 - val_loss: 1.9206e-04\n",
            "Epoch 21/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0021\n",
            "Epoch 21: val_loss did not improve from 0.00019\n",
            "29/29 [==============================] - 5s 156ms/step - loss: 0.0021 - val_loss: 2.9407e-04\n",
            "Epoch 22/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0028\n",
            "Epoch 22: val_loss did not improve from 0.00019\n",
            "29/29 [==============================] - 5s 156ms/step - loss: 0.0028 - val_loss: 0.0015\n",
            "Epoch 23/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0027\n",
            "Epoch 23: val_loss did not improve from 0.00019\n",
            "29/29 [==============================] - 5s 156ms/step - loss: 0.0027 - val_loss: 7.6103e-04\n",
            "Epoch 24/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0039\n",
            "Epoch 24: val_loss did not improve from 0.00019\n",
            "29/29 [==============================] - 5s 177ms/step - loss: 0.0039 - val_loss: 4.7589e-04\n",
            "Epoch 25/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0021\n",
            "Epoch 25: val_loss did not improve from 0.00019\n",
            "29/29 [==============================] - 4s 155ms/step - loss: 0.0021 - val_loss: 1.9902e-04\n",
            "Epoch 26/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0020\n",
            "Epoch 26: val_loss did not improve from 0.00019\n",
            "29/29 [==============================] - 5s 157ms/step - loss: 0.0020 - val_loss: 2.8173e-04\n",
            "Epoch 27/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0017\n",
            "Epoch 27: val_loss did not improve from 0.00019\n",
            "29/29 [==============================] - 5s 156ms/step - loss: 0.0017 - val_loss: 2.3858e-04\n",
            "Epoch 28/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0018\n",
            "Epoch 28: val_loss did not improve from 0.00019\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 0.0018 - val_loss: 4.0990e-04\n",
            "Epoch 29/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0017\n",
            "Epoch 29: val_loss did not improve from 0.00019\n",
            "29/29 [==============================] - 4s 155ms/step - loss: 0.0017 - val_loss: 2.1798e-04\n",
            "Epoch 30/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0019\n",
            "Epoch 30: val_loss did not improve from 0.00019\n",
            "29/29 [==============================] - 4s 155ms/step - loss: 0.0019 - val_loss: 5.2645e-04\n",
            "Epoch 31/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0021\n",
            "Epoch 31: val_loss did not improve from 0.00019\n",
            "29/29 [==============================] - 5s 156ms/step - loss: 0.0021 - val_loss: 2.0574e-04\n",
            "Epoch 32/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0020\n",
            "Epoch 32: val_loss did not improve from 0.00019\n",
            "29/29 [==============================] - 4s 154ms/step - loss: 0.0020 - val_loss: 3.0865e-04\n",
            "Epoch 33/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0017\n",
            "Epoch 33: val_loss did not improve from 0.00019\n",
            "29/29 [==============================] - 5s 155ms/step - loss: 0.0017 - val_loss: 4.1995e-04\n",
            "Epoch 34/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0014\n",
            "Epoch 34: val_loss improved from 0.00019 to 0.00019, saving model to saved_models/Stock.hdf5\n",
            "29/29 [==============================] - 4s 155ms/step - loss: 0.0014 - val_loss: 1.8722e-04\n",
            "Epoch 35/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0019\n",
            "Epoch 35: val_loss did not improve from 0.00019\n",
            "29/29 [==============================] - 5s 155ms/step - loss: 0.0019 - val_loss: 0.0011\n",
            "Epoch 36/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0023\n",
            "Epoch 36: val_loss did not improve from 0.00019\n",
            "29/29 [==============================] - 4s 154ms/step - loss: 0.0023 - val_loss: 2.0657e-04\n",
            "Epoch 37/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0021\n",
            "Epoch 37: val_loss did not improve from 0.00019\n",
            "29/29 [==============================] - 4s 152ms/step - loss: 0.0021 - val_loss: 3.2245e-04\n",
            "Epoch 38/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0016\n",
            "Epoch 38: val_loss did not improve from 0.00019\n",
            "29/29 [==============================] - 4s 153ms/step - loss: 0.0016 - val_loss: 2.3141e-04\n",
            "Epoch 39/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0018\n",
            "Epoch 39: val_loss did not improve from 0.00019\n",
            "29/29 [==============================] - 5s 157ms/step - loss: 0.0018 - val_loss: 2.2164e-04\n",
            "Epoch 40/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0018\n",
            "Epoch 40: val_loss did not improve from 0.00019\n",
            "29/29 [==============================] - 5s 156ms/step - loss: 0.0018 - val_loss: 5.8485e-04\n",
            "Epoch 41/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0026\n",
            "Epoch 41: val_loss did not improve from 0.00019\n",
            "29/29 [==============================] - 5s 156ms/step - loss: 0.0026 - val_loss: 3.7516e-04\n",
            "Epoch 42/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0021\n",
            "Epoch 42: val_loss did not improve from 0.00019\n",
            "29/29 [==============================] - 4s 155ms/step - loss: 0.0021 - val_loss: 5.7017e-04\n",
            "Epoch 43/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0018\n",
            "Epoch 43: val_loss improved from 0.00019 to 0.00015, saving model to saved_models/Stock.hdf5\n",
            "29/29 [==============================] - 5s 155ms/step - loss: 0.0018 - val_loss: 1.5461e-04\n",
            "Epoch 44/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0025\n",
            "Epoch 44: val_loss did not improve from 0.00015\n",
            "29/29 [==============================] - 4s 153ms/step - loss: 0.0025 - val_loss: 6.1741e-04\n",
            "Epoch 45/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0016\n",
            "Epoch 45: val_loss did not improve from 0.00015\n",
            "29/29 [==============================] - 4s 153ms/step - loss: 0.0016 - val_loss: 2.3402e-04\n",
            "Epoch 46/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0016\n",
            "Epoch 46: val_loss did not improve from 0.00015\n",
            "29/29 [==============================] - 4s 153ms/step - loss: 0.0016 - val_loss: 2.3698e-04\n",
            "Epoch 47/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0015\n",
            "Epoch 47: val_loss improved from 0.00015 to 0.00014, saving model to saved_models/Stock.hdf5\n",
            "29/29 [==============================] - 5s 158ms/step - loss: 0.0015 - val_loss: 1.4118e-04\n",
            "Epoch 48/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0014\n",
            "Epoch 48: val_loss did not improve from 0.00014\n",
            "29/29 [==============================] - 5s 174ms/step - loss: 0.0014 - val_loss: 1.5513e-04\n",
            "Epoch 49/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0013\n",
            "Epoch 49: val_loss did not improve from 0.00014\n",
            "29/29 [==============================] - 5s 160ms/step - loss: 0.0013 - val_loss: 3.3940e-04\n",
            "Epoch 50/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0013\n",
            "Epoch 50: val_loss did not improve from 0.00014\n",
            "29/29 [==============================] - 4s 154ms/step - loss: 0.0013 - val_loss: 2.9937e-04\n",
            "Epoch 51/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0014\n",
            "Epoch 51: val_loss did not improve from 0.00014\n",
            "29/29 [==============================] - 5s 157ms/step - loss: 0.0014 - val_loss: 2.6982e-04\n",
            "Epoch 52/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0013\n",
            "Epoch 52: val_loss did not improve from 0.00014\n",
            "29/29 [==============================] - 5s 162ms/step - loss: 0.0013 - val_loss: 1.7379e-04\n",
            "Epoch 53/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0014\n",
            "Epoch 53: val_loss did not improve from 0.00014\n",
            "29/29 [==============================] - 5s 159ms/step - loss: 0.0014 - val_loss: 1.4942e-04\n",
            "Epoch 54/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0011\n",
            "Epoch 54: val_loss did not improve from 0.00014\n",
            "29/29 [==============================] - 5s 155ms/step - loss: 0.0011 - val_loss: 1.6121e-04\n",
            "Epoch 55/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0012\n",
            "Epoch 55: val_loss did not improve from 0.00014\n",
            "29/29 [==============================] - 5s 157ms/step - loss: 0.0012 - val_loss: 1.4963e-04\n",
            "Epoch 56/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0011\n",
            "Epoch 56: val_loss did not improve from 0.00014\n",
            "29/29 [==============================] - 5s 160ms/step - loss: 0.0011 - val_loss: 2.1245e-04\n",
            "Epoch 57/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0011\n",
            "Epoch 57: val_loss did not improve from 0.00014\n",
            "29/29 [==============================] - 5s 156ms/step - loss: 0.0011 - val_loss: 1.5261e-04\n",
            "Epoch 58/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0011\n",
            "Epoch 58: val_loss did not improve from 0.00014\n",
            "29/29 [==============================] - 4s 154ms/step - loss: 0.0011 - val_loss: 2.2566e-04\n",
            "Epoch 59/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 9.9855e-04\n",
            "Epoch 59: val_loss did not improve from 0.00014\n",
            "29/29 [==============================] - 4s 153ms/step - loss: 9.9855e-04 - val_loss: 1.4206e-04\n",
            "Epoch 60/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 9.6291e-04\n",
            "Epoch 60: val_loss did not improve from 0.00014\n",
            "29/29 [==============================] - 4s 153ms/step - loss: 9.6291e-04 - val_loss: 2.2335e-04\n",
            "Epoch 61/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0014\n",
            "Epoch 61: val_loss did not improve from 0.00014\n",
            "29/29 [==============================] - 5s 156ms/step - loss: 0.0014 - val_loss: 1.9212e-04\n",
            "Epoch 62/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0010\n",
            "Epoch 62: val_loss did not improve from 0.00014\n",
            "29/29 [==============================] - 5s 156ms/step - loss: 0.0010 - val_loss: 1.5201e-04\n",
            "Epoch 63/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 9.8750e-04\n",
            "Epoch 63: val_loss did not improve from 0.00014\n",
            "29/29 [==============================] - 4s 154ms/step - loss: 9.8750e-04 - val_loss: 1.5038e-04\n",
            "Epoch 64/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0010\n",
            "Epoch 64: val_loss did not improve from 0.00014\n",
            "29/29 [==============================] - 5s 156ms/step - loss: 0.0010 - val_loss: 1.5733e-04\n",
            "Epoch 65/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0012\n",
            "Epoch 65: val_loss did not improve from 0.00014\n",
            "29/29 [==============================] - 4s 155ms/step - loss: 0.0012 - val_loss: 1.7104e-04\n",
            "Epoch 66/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0010    \n",
            "Epoch 66: val_loss improved from 0.00014 to 0.00013, saving model to saved_models/Stock.hdf5\n",
            "29/29 [==============================] - 5s 157ms/step - loss: 0.0010 - val_loss: 1.3373e-04\n",
            "Epoch 67/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0011\n",
            "Epoch 67: val_loss did not improve from 0.00013\n",
            "29/29 [==============================] - 4s 155ms/step - loss: 0.0011 - val_loss: 3.2658e-04\n",
            "Epoch 68/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 9.9091e-04\n",
            "Epoch 68: val_loss did not improve from 0.00013\n",
            "29/29 [==============================] - 4s 153ms/step - loss: 9.9091e-04 - val_loss: 1.3985e-04\n",
            "Epoch 69/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0011\n",
            "Epoch 69: val_loss did not improve from 0.00013\n",
            "29/29 [==============================] - 5s 158ms/step - loss: 0.0011 - val_loss: 1.9472e-04\n",
            "Epoch 70/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0013\n",
            "Epoch 70: val_loss did not improve from 0.00013\n",
            "29/29 [==============================] - 5s 157ms/step - loss: 0.0013 - val_loss: 2.1370e-04\n",
            "Epoch 71/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0011\n",
            "Epoch 71: val_loss did not improve from 0.00013\n",
            "29/29 [==============================] - 4s 154ms/step - loss: 0.0011 - val_loss: 2.7414e-04\n",
            "Epoch 72/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0011\n",
            "Epoch 72: val_loss did not improve from 0.00013\n",
            "29/29 [==============================] - 5s 157ms/step - loss: 0.0011 - val_loss: 1.3817e-04\n",
            "Epoch 73/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0011\n",
            "Epoch 73: val_loss did not improve from 0.00013\n",
            "29/29 [==============================] - 5s 156ms/step - loss: 0.0011 - val_loss: 1.4605e-04\n",
            "Epoch 74/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 9.4828e-04\n",
            "Epoch 74: val_loss did not improve from 0.00013\n",
            "29/29 [==============================] - 5s 156ms/step - loss: 9.4828e-04 - val_loss: 1.4629e-04\n",
            "Epoch 75/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 9.0100e-04\n",
            "Epoch 75: val_loss did not improve from 0.00013\n",
            "29/29 [==============================] - 5s 157ms/step - loss: 9.0100e-04 - val_loss: 1.5534e-04\n",
            "Epoch 76/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 8.1074e-04\n",
            "Epoch 76: val_loss did not improve from 0.00013\n",
            "29/29 [==============================] - 5s 156ms/step - loss: 8.1074e-04 - val_loss: 1.4087e-04\n",
            "Epoch 77/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0010\n",
            "Epoch 77: val_loss did not improve from 0.00013\n",
            "29/29 [==============================] - 4s 154ms/step - loss: 0.0010 - val_loss: 1.4360e-04\n",
            "Epoch 78/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 8.4358e-04\n",
            "Epoch 78: val_loss did not improve from 0.00013\n",
            "29/29 [==============================] - 4s 152ms/step - loss: 8.4358e-04 - val_loss: 1.3516e-04\n",
            "Epoch 79/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 9.5360e-04\n",
            "Epoch 79: val_loss did not improve from 0.00013\n",
            "29/29 [==============================] - 4s 154ms/step - loss: 9.5360e-04 - val_loss: 2.1766e-04\n",
            "Epoch 80/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 9.3583e-04\n",
            "Epoch 80: val_loss did not improve from 0.00013\n",
            "29/29 [==============================] - 5s 157ms/step - loss: 9.3583e-04 - val_loss: 1.3702e-04\n",
            "Epoch 81/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0011\n",
            "Epoch 81: val_loss improved from 0.00013 to 0.00013, saving model to saved_models/Stock.hdf5\n",
            "29/29 [==============================] - 5s 157ms/step - loss: 0.0011 - val_loss: 1.3223e-04\n",
            "Epoch 82/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0014\n",
            "Epoch 82: val_loss did not improve from 0.00013\n",
            "29/29 [==============================] - 5s 157ms/step - loss: 0.0014 - val_loss: 4.9554e-04\n",
            "Epoch 83/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0012\n",
            "Epoch 83: val_loss did not improve from 0.00013\n",
            "29/29 [==============================] - 5s 156ms/step - loss: 0.0012 - val_loss: 3.1624e-04\n",
            "Epoch 84/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0011\n",
            "Epoch 84: val_loss did not improve from 0.00013\n",
            "29/29 [==============================] - 5s 156ms/step - loss: 0.0011 - val_loss: 3.4554e-04\n",
            "Epoch 85/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0011\n",
            "Epoch 85: val_loss improved from 0.00013 to 0.00013, saving model to saved_models/Stock.hdf5\n",
            "29/29 [==============================] - 5s 156ms/step - loss: 0.0011 - val_loss: 1.2941e-04\n",
            "Epoch 86/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 9.1743e-04\n",
            "Epoch 86: val_loss did not improve from 0.00013\n",
            "29/29 [==============================] - 5s 155ms/step - loss: 9.1743e-04 - val_loss: 1.4225e-04\n",
            "Epoch 87/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0011\n",
            "Epoch 87: val_loss did not improve from 0.00013\n",
            "29/29 [==============================] - 4s 155ms/step - loss: 0.0011 - val_loss: 1.8785e-04\n",
            "Epoch 88/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0013\n",
            "Epoch 88: val_loss improved from 0.00013 to 0.00012, saving model to saved_models/Stock.hdf5\n",
            "29/29 [==============================] - 5s 157ms/step - loss: 0.0013 - val_loss: 1.2090e-04\n",
            "Epoch 89/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0011\n",
            "Epoch 89: val_loss did not improve from 0.00012\n",
            "29/29 [==============================] - 5s 158ms/step - loss: 0.0011 - val_loss: 1.3698e-04\n",
            "Epoch 90/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 9.6539e-04\n",
            "Epoch 90: val_loss did not improve from 0.00012\n",
            "29/29 [==============================] - 5s 158ms/step - loss: 9.6539e-04 - val_loss: 1.8004e-04\n",
            "Epoch 91/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 8.5440e-04\n",
            "Epoch 91: val_loss did not improve from 0.00012\n",
            "29/29 [==============================] - 4s 154ms/step - loss: 8.5440e-04 - val_loss: 1.2221e-04\n",
            "Epoch 92/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 8.9257e-04\n",
            "Epoch 92: val_loss did not improve from 0.00012\n",
            "29/29 [==============================] - 4s 154ms/step - loss: 8.9257e-04 - val_loss: 2.3838e-04\n",
            "Epoch 93/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0010\n",
            "Epoch 93: val_loss did not improve from 0.00012\n",
            "29/29 [==============================] - 4s 154ms/step - loss: 0.0010 - val_loss: 2.1761e-04\n",
            "Epoch 94/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 9.5405e-04\n",
            "Epoch 94: val_loss did not improve from 0.00012\n",
            "29/29 [==============================] - 4s 155ms/step - loss: 9.5405e-04 - val_loss: 1.2928e-04\n",
            "Epoch 95/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0012\n",
            "Epoch 95: val_loss did not improve from 0.00012\n",
            "29/29 [==============================] - 5s 157ms/step - loss: 0.0012 - val_loss: 2.4405e-04\n",
            "Epoch 96/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0012\n",
            "Epoch 96: val_loss did not improve from 0.00012\n",
            "29/29 [==============================] - 5s 158ms/step - loss: 0.0012 - val_loss: 1.8656e-04\n",
            "Epoch 97/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0012\n",
            "Epoch 97: val_loss did not improve from 0.00012\n",
            "29/29 [==============================] - 5s 156ms/step - loss: 0.0012 - val_loss: 3.3199e-04\n",
            "Epoch 98/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.0010\n",
            "Epoch 98: val_loss did not improve from 0.00012\n",
            "29/29 [==============================] - 5s 157ms/step - loss: 0.0010 - val_loss: 1.3845e-04\n",
            "Epoch 99/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 9.9448e-04\n",
            "Epoch 99: val_loss did not improve from 0.00012\n",
            "29/29 [==============================] - 5s 155ms/step - loss: 9.9448e-04 - val_loss: 2.4850e-04\n",
            "Epoch 100/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 9.4098e-04\n",
            "Epoch 100: val_loss did not improve from 0.00012\n",
            "29/29 [==============================] - 5s 156ms/step - loss: 9.4098e-04 - val_loss: 1.3499e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7ceae4ea10>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict=model.predict(X_train)\n",
        "test_predict=model.predict(X_test)"
      ],
      "metadata": {
        "id": "zutA8KoTlJLm"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict=scaler.inverse_transform(train_predict)\n",
        "test_predict=scaler.inverse_transform(test_predict)"
      ],
      "metadata": {
        "id": "KM_iIfXxodcB"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from sklearn.metrics import mean_squared_error\n",
        "math.sqrt(mean_squared_error(y_train,train_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPIZRdgRokkN",
        "outputId": "69bbe47a-ea57-4da6-b99d-0b6db4c4bda8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "216.31593204104692"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "math.sqrt(mean_squared_error(ytest,test_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSfQFR43orVk",
        "outputId": "724b77be-aee5-4918-ac5c-024bdb9fa93c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "164.81674859505762"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "look_back=100\n",
        "trainPredictPlot = np.empty_like(df1)\n",
        "trainPredictPlot[:, :] = np.nan\n",
        "trainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = np.empty_like(df1)\n",
        "testPredictPlot[:, :] = np.nan\n",
        "testPredictPlot[len(train_predict)+(look_back*2)+1:len(df1)-1, :] = test_predict\n",
        "# plot baseline and predictions\n",
        "plt.plot(scaler.inverse_transform(df1))\n",
        "plt.plot(trainPredictPlot)\n",
        "plt.plot(testPredictPlot)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "g2xUEcS_oxrz",
        "outputId": "0cb713cd-d6f2-41f8-9ed2-1d274f605eb2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isabWu5no5dF",
        "outputId": "0544a816-ca04-4402-ee05-518c92119179"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "252"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_input=test_data[152:].reshape(1,-1)\n",
        "x_input.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpaScPDQpUJ1",
        "outputId": "85e5c318-dda7-4af5-e8f8-30e09b482fcc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_input=list(x_input)\n",
        "temp_input=temp_input[0].tolist()"
      ],
      "metadata": {
        "id": "tJ6SDAQypal2"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZ0FgPyfpesH",
        "outputId": "b558b49d-a0fc-4b16-a276-7edb9ad024d6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1611521603005635,\n",
              " 0.17092047589229803,\n",
              " 0.16961803381340007,\n",
              " 0.18186599874765175,\n",
              " 0.17257357545397617,\n",
              " 0.16904195366311836,\n",
              " 0.1814902943018159,\n",
              " 0.1638572323105823,\n",
              " 0.16105197244834057,\n",
              " 0.1575704445835942,\n",
              " 0.1656856606136506,\n",
              " 0.1723231058234188,\n",
              " 0.17392611145898557,\n",
              " 0.18407013149655604,\n",
              " 0.18146524733876013,\n",
              " 0.1816906700062617,\n",
              " 0.1787351283656856,\n",
              " 0.17715716969317463,\n",
              " 0.18827802128991855,\n",
              " 0.182492172824045,\n",
              " 0.1705197244834063,\n",
              " 0.16320601127113332,\n",
              " 0.16363180964308072,\n",
              " 0.1636819035691922,\n",
              " 0.17092047589229803,\n",
              " 0.17204758922980584,\n",
              " 0.1636819035691922,\n",
              " 0.1658860363180964,\n",
              " 0.15769567939887286,\n",
              " 0.1487539135879774,\n",
              " 0.1444458359423919,\n",
              " 0.13918597370068875,\n",
              " 0.13720726361928615,\n",
              " 0.1325986224170319,\n",
              " 0.13237319974953032,\n",
              " 0.13119599248591102,\n",
              " 0.15902316844082653,\n",
              " 0.17016906700062612,\n",
              " 0.16974326862867878,\n",
              " 0.17282404508453347,\n",
              " 0.165460237946149,\n",
              " 0.16418284283030676,\n",
              " 0.16235441452723853,\n",
              " 0.17029430181590482,\n",
              " 0.17392611145898557,\n",
              " 0.16350657482780212,\n",
              " 0.1547902316844082,\n",
              " 0.15539135879774574,\n",
              " 0.16518472135253592,\n",
              " 0.1645835942391985,\n",
              " 0.15539135879774574,\n",
              " 0.15143393863494048,\n",
              " 0.14396994364433308,\n",
              " 0.13332498434564805,\n",
              " 0.14001252348152782,\n",
              " 0.14529743268628675,\n",
              " 0.14597370068879145,\n",
              " 0.14116468378209135,\n",
              " 0.14958046336881647,\n",
              " 0.1487539135879774,\n",
              " 0.14108954289292414,\n",
              " 0.13139636819035688,\n",
              " 0.1267376330619912,\n",
              " 0.1405385097056981,\n",
              " 0.12944270507201,\n",
              " 0.11994990607388845,\n",
              " 0.10965560425798371,\n",
              " 0.12085159674389478,\n",
              " 0.13212273011897302,\n",
              " 0.13470256731371316,\n",
              " 0.14311834690043823,\n",
              " 0.14662492172824038,\n",
              " 0.1552410770194113,\n",
              " 0.1587226048841578,\n",
              " 0.16839073262366933,\n",
              " 0.17001878522229175,\n",
              " 0.17222291797119593,\n",
              " 0.18063869755792106,\n",
              " 0.1776581089542893,\n",
              " 0.16974326862867878,\n",
              " 0.16899185973700687,\n",
              " 0.1793362554790231,\n",
              " 0.17087038196618654,\n",
              " 0.16278021289918598,\n",
              " 0.1635566687539135,\n",
              " 0.158422041327489,\n",
              " 0.14755165936130238,\n",
              " 0.1523356293049467,\n",
              " 0.15919849718221663,\n",
              " 0.14639949906073885,\n",
              " 0.1458484658735128,\n",
              " 0.15168440826549778,\n",
              " 0.15125860989355033,\n",
              " 0.14922980588603624,\n",
              " 0.13763306199123349,\n",
              " 0.140363180964308,\n",
              " 0.1251346274264245,\n",
              " 0.12455854727614268,\n",
              " 0.14226675015654344,\n",
              " 0.12726361928616153]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lst_output=[]\n",
        "n_steps=100\n",
        "i=0\n",
        "while(i<30):\n",
        "    \n",
        "    if(len(temp_input)>100):\n",
        "        #print(temp_input)\n",
        "        x_input=np.array(temp_input[1:])\n",
        "        print(\"{} day input {}\".format(i,x_input))\n",
        "        x_input=x_input.reshape(1,-1)\n",
        "        x_input = x_input.reshape((1, n_steps, 1))\n",
        "        #print(x_input)\n",
        "        yhat = model.predict(x_input, verbose=0)\n",
        "        print(\"{} day output {}\".format(i,yhat))\n",
        "        temp_input.extend(yhat[0].tolist())\n",
        "        temp_input=temp_input[1:]\n",
        "        #print(temp_input)\n",
        "        lst_output.extend(yhat.tolist())\n",
        "        i=i+1\n",
        "    else:\n",
        "        x_input = x_input.reshape((1, n_steps,1))\n",
        "        yhat = model.predict(x_input, verbose=0)\n",
        "        print(yhat[0])\n",
        "        temp_input.extend(yhat[0].tolist())\n",
        "        print(len(temp_input))\n",
        "        lst_output.extend(yhat.tolist())\n",
        "        i=i+1\n",
        "    \n",
        "\n",
        "print(lst_output)"
      ],
      "metadata": {
        "id": "CO5bVkUVpie0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01afb9bf-38d2-489c-a7e9-53efd727a9c9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.13684094]\n",
            "101\n",
            "1 day input [0.17092048 0.16961803 0.181866   0.17257358 0.16904195 0.18149029\n",
            " 0.16385723 0.16105197 0.15757044 0.16568566 0.17232311 0.17392611\n",
            " 0.18407013 0.18146525 0.18169067 0.17873513 0.17715717 0.18827802\n",
            " 0.18249217 0.17051972 0.16320601 0.16363181 0.1636819  0.17092048\n",
            " 0.17204759 0.1636819  0.16588604 0.15769568 0.14875391 0.14444584\n",
            " 0.13918597 0.13720726 0.13259862 0.1323732  0.13119599 0.15902317\n",
            " 0.17016907 0.16974327 0.17282405 0.16546024 0.16418284 0.16235441\n",
            " 0.1702943  0.17392611 0.16350657 0.15479023 0.15539136 0.16518472\n",
            " 0.16458359 0.15539136 0.15143394 0.14396994 0.13332498 0.14001252\n",
            " 0.14529743 0.1459737  0.14116468 0.14958046 0.14875391 0.14108954\n",
            " 0.13139637 0.12673763 0.14053851 0.12944271 0.11994991 0.1096556\n",
            " 0.1208516  0.13212273 0.13470257 0.14311835 0.14662492 0.15524108\n",
            " 0.1587226  0.16839073 0.17001879 0.17222292 0.1806387  0.17765811\n",
            " 0.16974327 0.16899186 0.17933626 0.17087038 0.16278021 0.16355667\n",
            " 0.15842204 0.14755166 0.15233563 0.1591985  0.1463995  0.14584847\n",
            " 0.15168441 0.15125861 0.14922981 0.13763306 0.14036318 0.12513463\n",
            " 0.12455855 0.14226675 0.12726362 0.13684094]\n",
            "1 day output [[0.13703962]]\n",
            "2 day input [0.16961803 0.181866   0.17257358 0.16904195 0.18149029 0.16385723\n",
            " 0.16105197 0.15757044 0.16568566 0.17232311 0.17392611 0.18407013\n",
            " 0.18146525 0.18169067 0.17873513 0.17715717 0.18827802 0.18249217\n",
            " 0.17051972 0.16320601 0.16363181 0.1636819  0.17092048 0.17204759\n",
            " 0.1636819  0.16588604 0.15769568 0.14875391 0.14444584 0.13918597\n",
            " 0.13720726 0.13259862 0.1323732  0.13119599 0.15902317 0.17016907\n",
            " 0.16974327 0.17282405 0.16546024 0.16418284 0.16235441 0.1702943\n",
            " 0.17392611 0.16350657 0.15479023 0.15539136 0.16518472 0.16458359\n",
            " 0.15539136 0.15143394 0.14396994 0.13332498 0.14001252 0.14529743\n",
            " 0.1459737  0.14116468 0.14958046 0.14875391 0.14108954 0.13139637\n",
            " 0.12673763 0.14053851 0.12944271 0.11994991 0.1096556  0.1208516\n",
            " 0.13212273 0.13470257 0.14311835 0.14662492 0.15524108 0.1587226\n",
            " 0.16839073 0.17001879 0.17222292 0.1806387  0.17765811 0.16974327\n",
            " 0.16899186 0.17933626 0.17087038 0.16278021 0.16355667 0.15842204\n",
            " 0.14755166 0.15233563 0.1591985  0.1463995  0.14584847 0.15168441\n",
            " 0.15125861 0.14922981 0.13763306 0.14036318 0.12513463 0.12455855\n",
            " 0.14226675 0.12726362 0.13684094 0.13703962]\n",
            "2 day output [[0.13815281]]\n",
            "3 day input [0.181866   0.17257358 0.16904195 0.18149029 0.16385723 0.16105197\n",
            " 0.15757044 0.16568566 0.17232311 0.17392611 0.18407013 0.18146525\n",
            " 0.18169067 0.17873513 0.17715717 0.18827802 0.18249217 0.17051972\n",
            " 0.16320601 0.16363181 0.1636819  0.17092048 0.17204759 0.1636819\n",
            " 0.16588604 0.15769568 0.14875391 0.14444584 0.13918597 0.13720726\n",
            " 0.13259862 0.1323732  0.13119599 0.15902317 0.17016907 0.16974327\n",
            " 0.17282405 0.16546024 0.16418284 0.16235441 0.1702943  0.17392611\n",
            " 0.16350657 0.15479023 0.15539136 0.16518472 0.16458359 0.15539136\n",
            " 0.15143394 0.14396994 0.13332498 0.14001252 0.14529743 0.1459737\n",
            " 0.14116468 0.14958046 0.14875391 0.14108954 0.13139637 0.12673763\n",
            " 0.14053851 0.12944271 0.11994991 0.1096556  0.1208516  0.13212273\n",
            " 0.13470257 0.14311835 0.14662492 0.15524108 0.1587226  0.16839073\n",
            " 0.17001879 0.17222292 0.1806387  0.17765811 0.16974327 0.16899186\n",
            " 0.17933626 0.17087038 0.16278021 0.16355667 0.15842204 0.14755166\n",
            " 0.15233563 0.1591985  0.1463995  0.14584847 0.15168441 0.15125861\n",
            " 0.14922981 0.13763306 0.14036318 0.12513463 0.12455855 0.14226675\n",
            " 0.12726362 0.13684094 0.13703962 0.13815281]\n",
            "3 day output [[0.13969348]]\n",
            "4 day input [0.17257358 0.16904195 0.18149029 0.16385723 0.16105197 0.15757044\n",
            " 0.16568566 0.17232311 0.17392611 0.18407013 0.18146525 0.18169067\n",
            " 0.17873513 0.17715717 0.18827802 0.18249217 0.17051972 0.16320601\n",
            " 0.16363181 0.1636819  0.17092048 0.17204759 0.1636819  0.16588604\n",
            " 0.15769568 0.14875391 0.14444584 0.13918597 0.13720726 0.13259862\n",
            " 0.1323732  0.13119599 0.15902317 0.17016907 0.16974327 0.17282405\n",
            " 0.16546024 0.16418284 0.16235441 0.1702943  0.17392611 0.16350657\n",
            " 0.15479023 0.15539136 0.16518472 0.16458359 0.15539136 0.15143394\n",
            " 0.14396994 0.13332498 0.14001252 0.14529743 0.1459737  0.14116468\n",
            " 0.14958046 0.14875391 0.14108954 0.13139637 0.12673763 0.14053851\n",
            " 0.12944271 0.11994991 0.1096556  0.1208516  0.13212273 0.13470257\n",
            " 0.14311835 0.14662492 0.15524108 0.1587226  0.16839073 0.17001879\n",
            " 0.17222292 0.1806387  0.17765811 0.16974327 0.16899186 0.17933626\n",
            " 0.17087038 0.16278021 0.16355667 0.15842204 0.14755166 0.15233563\n",
            " 0.1591985  0.1463995  0.14584847 0.15168441 0.15125861 0.14922981\n",
            " 0.13763306 0.14036318 0.12513463 0.12455855 0.14226675 0.12726362\n",
            " 0.13684094 0.13703962 0.13815281 0.13969348]\n",
            "4 day output [[0.14139517]]\n",
            "5 day input [0.16904195 0.18149029 0.16385723 0.16105197 0.15757044 0.16568566\n",
            " 0.17232311 0.17392611 0.18407013 0.18146525 0.18169067 0.17873513\n",
            " 0.17715717 0.18827802 0.18249217 0.17051972 0.16320601 0.16363181\n",
            " 0.1636819  0.17092048 0.17204759 0.1636819  0.16588604 0.15769568\n",
            " 0.14875391 0.14444584 0.13918597 0.13720726 0.13259862 0.1323732\n",
            " 0.13119599 0.15902317 0.17016907 0.16974327 0.17282405 0.16546024\n",
            " 0.16418284 0.16235441 0.1702943  0.17392611 0.16350657 0.15479023\n",
            " 0.15539136 0.16518472 0.16458359 0.15539136 0.15143394 0.14396994\n",
            " 0.13332498 0.14001252 0.14529743 0.1459737  0.14116468 0.14958046\n",
            " 0.14875391 0.14108954 0.13139637 0.12673763 0.14053851 0.12944271\n",
            " 0.11994991 0.1096556  0.1208516  0.13212273 0.13470257 0.14311835\n",
            " 0.14662492 0.15524108 0.1587226  0.16839073 0.17001879 0.17222292\n",
            " 0.1806387  0.17765811 0.16974327 0.16899186 0.17933626 0.17087038\n",
            " 0.16278021 0.16355667 0.15842204 0.14755166 0.15233563 0.1591985\n",
            " 0.1463995  0.14584847 0.15168441 0.15125861 0.14922981 0.13763306\n",
            " 0.14036318 0.12513463 0.12455855 0.14226675 0.12726362 0.13684094\n",
            " 0.13703962 0.13815281 0.13969348 0.14139517]\n",
            "5 day output [[0.1431365]]\n",
            "6 day input [0.18149029 0.16385723 0.16105197 0.15757044 0.16568566 0.17232311\n",
            " 0.17392611 0.18407013 0.18146525 0.18169067 0.17873513 0.17715717\n",
            " 0.18827802 0.18249217 0.17051972 0.16320601 0.16363181 0.1636819\n",
            " 0.17092048 0.17204759 0.1636819  0.16588604 0.15769568 0.14875391\n",
            " 0.14444584 0.13918597 0.13720726 0.13259862 0.1323732  0.13119599\n",
            " 0.15902317 0.17016907 0.16974327 0.17282405 0.16546024 0.16418284\n",
            " 0.16235441 0.1702943  0.17392611 0.16350657 0.15479023 0.15539136\n",
            " 0.16518472 0.16458359 0.15539136 0.15143394 0.14396994 0.13332498\n",
            " 0.14001252 0.14529743 0.1459737  0.14116468 0.14958046 0.14875391\n",
            " 0.14108954 0.13139637 0.12673763 0.14053851 0.12944271 0.11994991\n",
            " 0.1096556  0.1208516  0.13212273 0.13470257 0.14311835 0.14662492\n",
            " 0.15524108 0.1587226  0.16839073 0.17001879 0.17222292 0.1806387\n",
            " 0.17765811 0.16974327 0.16899186 0.17933626 0.17087038 0.16278021\n",
            " 0.16355667 0.15842204 0.14755166 0.15233563 0.1591985  0.1463995\n",
            " 0.14584847 0.15168441 0.15125861 0.14922981 0.13763306 0.14036318\n",
            " 0.12513463 0.12455855 0.14226675 0.12726362 0.13684094 0.13703962\n",
            " 0.13815281 0.13969348 0.14139517 0.1431365 ]\n",
            "6 day output [[0.14486526]]\n",
            "7 day input [0.16385723 0.16105197 0.15757044 0.16568566 0.17232311 0.17392611\n",
            " 0.18407013 0.18146525 0.18169067 0.17873513 0.17715717 0.18827802\n",
            " 0.18249217 0.17051972 0.16320601 0.16363181 0.1636819  0.17092048\n",
            " 0.17204759 0.1636819  0.16588604 0.15769568 0.14875391 0.14444584\n",
            " 0.13918597 0.13720726 0.13259862 0.1323732  0.13119599 0.15902317\n",
            " 0.17016907 0.16974327 0.17282405 0.16546024 0.16418284 0.16235441\n",
            " 0.1702943  0.17392611 0.16350657 0.15479023 0.15539136 0.16518472\n",
            " 0.16458359 0.15539136 0.15143394 0.14396994 0.13332498 0.14001252\n",
            " 0.14529743 0.1459737  0.14116468 0.14958046 0.14875391 0.14108954\n",
            " 0.13139637 0.12673763 0.14053851 0.12944271 0.11994991 0.1096556\n",
            " 0.1208516  0.13212273 0.13470257 0.14311835 0.14662492 0.15524108\n",
            " 0.1587226  0.16839073 0.17001879 0.17222292 0.1806387  0.17765811\n",
            " 0.16974327 0.16899186 0.17933626 0.17087038 0.16278021 0.16355667\n",
            " 0.15842204 0.14755166 0.15233563 0.1591985  0.1463995  0.14584847\n",
            " 0.15168441 0.15125861 0.14922981 0.13763306 0.14036318 0.12513463\n",
            " 0.12455855 0.14226675 0.12726362 0.13684094 0.13703962 0.13815281\n",
            " 0.13969348 0.14139517 0.1431365  0.14486526]\n",
            "7 day output [[0.14655934]]\n",
            "8 day input [0.16105197 0.15757044 0.16568566 0.17232311 0.17392611 0.18407013\n",
            " 0.18146525 0.18169067 0.17873513 0.17715717 0.18827802 0.18249217\n",
            " 0.17051972 0.16320601 0.16363181 0.1636819  0.17092048 0.17204759\n",
            " 0.1636819  0.16588604 0.15769568 0.14875391 0.14444584 0.13918597\n",
            " 0.13720726 0.13259862 0.1323732  0.13119599 0.15902317 0.17016907\n",
            " 0.16974327 0.17282405 0.16546024 0.16418284 0.16235441 0.1702943\n",
            " 0.17392611 0.16350657 0.15479023 0.15539136 0.16518472 0.16458359\n",
            " 0.15539136 0.15143394 0.14396994 0.13332498 0.14001252 0.14529743\n",
            " 0.1459737  0.14116468 0.14958046 0.14875391 0.14108954 0.13139637\n",
            " 0.12673763 0.14053851 0.12944271 0.11994991 0.1096556  0.1208516\n",
            " 0.13212273 0.13470257 0.14311835 0.14662492 0.15524108 0.1587226\n",
            " 0.16839073 0.17001879 0.17222292 0.1806387  0.17765811 0.16974327\n",
            " 0.16899186 0.17933626 0.17087038 0.16278021 0.16355667 0.15842204\n",
            " 0.14755166 0.15233563 0.1591985  0.1463995  0.14584847 0.15168441\n",
            " 0.15125861 0.14922981 0.13763306 0.14036318 0.12513463 0.12455855\n",
            " 0.14226675 0.12726362 0.13684094 0.13703962 0.13815281 0.13969348\n",
            " 0.14139517 0.1431365  0.14486526 0.14655934]\n",
            "8 day output [[0.14821021]]\n",
            "9 day input [0.15757044 0.16568566 0.17232311 0.17392611 0.18407013 0.18146525\n",
            " 0.18169067 0.17873513 0.17715717 0.18827802 0.18249217 0.17051972\n",
            " 0.16320601 0.16363181 0.1636819  0.17092048 0.17204759 0.1636819\n",
            " 0.16588604 0.15769568 0.14875391 0.14444584 0.13918597 0.13720726\n",
            " 0.13259862 0.1323732  0.13119599 0.15902317 0.17016907 0.16974327\n",
            " 0.17282405 0.16546024 0.16418284 0.16235441 0.1702943  0.17392611\n",
            " 0.16350657 0.15479023 0.15539136 0.16518472 0.16458359 0.15539136\n",
            " 0.15143394 0.14396994 0.13332498 0.14001252 0.14529743 0.1459737\n",
            " 0.14116468 0.14958046 0.14875391 0.14108954 0.13139637 0.12673763\n",
            " 0.14053851 0.12944271 0.11994991 0.1096556  0.1208516  0.13212273\n",
            " 0.13470257 0.14311835 0.14662492 0.15524108 0.1587226  0.16839073\n",
            " 0.17001879 0.17222292 0.1806387  0.17765811 0.16974327 0.16899186\n",
            " 0.17933626 0.17087038 0.16278021 0.16355667 0.15842204 0.14755166\n",
            " 0.15233563 0.1591985  0.1463995  0.14584847 0.15168441 0.15125861\n",
            " 0.14922981 0.13763306 0.14036318 0.12513463 0.12455855 0.14226675\n",
            " 0.12726362 0.13684094 0.13703962 0.13815281 0.13969348 0.14139517\n",
            " 0.1431365  0.14486526 0.14655934 0.14821021]\n",
            "9 day output [[0.14981687]]\n",
            "10 day input [0.16568566 0.17232311 0.17392611 0.18407013 0.18146525 0.18169067\n",
            " 0.17873513 0.17715717 0.18827802 0.18249217 0.17051972 0.16320601\n",
            " 0.16363181 0.1636819  0.17092048 0.17204759 0.1636819  0.16588604\n",
            " 0.15769568 0.14875391 0.14444584 0.13918597 0.13720726 0.13259862\n",
            " 0.1323732  0.13119599 0.15902317 0.17016907 0.16974327 0.17282405\n",
            " 0.16546024 0.16418284 0.16235441 0.1702943  0.17392611 0.16350657\n",
            " 0.15479023 0.15539136 0.16518472 0.16458359 0.15539136 0.15143394\n",
            " 0.14396994 0.13332498 0.14001252 0.14529743 0.1459737  0.14116468\n",
            " 0.14958046 0.14875391 0.14108954 0.13139637 0.12673763 0.14053851\n",
            " 0.12944271 0.11994991 0.1096556  0.1208516  0.13212273 0.13470257\n",
            " 0.14311835 0.14662492 0.15524108 0.1587226  0.16839073 0.17001879\n",
            " 0.17222292 0.1806387  0.17765811 0.16974327 0.16899186 0.17933626\n",
            " 0.17087038 0.16278021 0.16355667 0.15842204 0.14755166 0.15233563\n",
            " 0.1591985  0.1463995  0.14584847 0.15168441 0.15125861 0.14922981\n",
            " 0.13763306 0.14036318 0.12513463 0.12455855 0.14226675 0.12726362\n",
            " 0.13684094 0.13703962 0.13815281 0.13969348 0.14139517 0.1431365\n",
            " 0.14486526 0.14655934 0.14821021 0.14981687]\n",
            "10 day output [[0.15138268]]\n",
            "11 day input [0.17232311 0.17392611 0.18407013 0.18146525 0.18169067 0.17873513\n",
            " 0.17715717 0.18827802 0.18249217 0.17051972 0.16320601 0.16363181\n",
            " 0.1636819  0.17092048 0.17204759 0.1636819  0.16588604 0.15769568\n",
            " 0.14875391 0.14444584 0.13918597 0.13720726 0.13259862 0.1323732\n",
            " 0.13119599 0.15902317 0.17016907 0.16974327 0.17282405 0.16546024\n",
            " 0.16418284 0.16235441 0.1702943  0.17392611 0.16350657 0.15479023\n",
            " 0.15539136 0.16518472 0.16458359 0.15539136 0.15143394 0.14396994\n",
            " 0.13332498 0.14001252 0.14529743 0.1459737  0.14116468 0.14958046\n",
            " 0.14875391 0.14108954 0.13139637 0.12673763 0.14053851 0.12944271\n",
            " 0.11994991 0.1096556  0.1208516  0.13212273 0.13470257 0.14311835\n",
            " 0.14662492 0.15524108 0.1587226  0.16839073 0.17001879 0.17222292\n",
            " 0.1806387  0.17765811 0.16974327 0.16899186 0.17933626 0.17087038\n",
            " 0.16278021 0.16355667 0.15842204 0.14755166 0.15233563 0.1591985\n",
            " 0.1463995  0.14584847 0.15168441 0.15125861 0.14922981 0.13763306\n",
            " 0.14036318 0.12513463 0.12455855 0.14226675 0.12726362 0.13684094\n",
            " 0.13703962 0.13815281 0.13969348 0.14139517 0.1431365  0.14486526\n",
            " 0.14655934 0.14821021 0.14981687 0.15138268]\n",
            "11 day output [[0.1529133]]\n",
            "12 day input [0.17392611 0.18407013 0.18146525 0.18169067 0.17873513 0.17715717\n",
            " 0.18827802 0.18249217 0.17051972 0.16320601 0.16363181 0.1636819\n",
            " 0.17092048 0.17204759 0.1636819  0.16588604 0.15769568 0.14875391\n",
            " 0.14444584 0.13918597 0.13720726 0.13259862 0.1323732  0.13119599\n",
            " 0.15902317 0.17016907 0.16974327 0.17282405 0.16546024 0.16418284\n",
            " 0.16235441 0.1702943  0.17392611 0.16350657 0.15479023 0.15539136\n",
            " 0.16518472 0.16458359 0.15539136 0.15143394 0.14396994 0.13332498\n",
            " 0.14001252 0.14529743 0.1459737  0.14116468 0.14958046 0.14875391\n",
            " 0.14108954 0.13139637 0.12673763 0.14053851 0.12944271 0.11994991\n",
            " 0.1096556  0.1208516  0.13212273 0.13470257 0.14311835 0.14662492\n",
            " 0.15524108 0.1587226  0.16839073 0.17001879 0.17222292 0.1806387\n",
            " 0.17765811 0.16974327 0.16899186 0.17933626 0.17087038 0.16278021\n",
            " 0.16355667 0.15842204 0.14755166 0.15233563 0.1591985  0.1463995\n",
            " 0.14584847 0.15168441 0.15125861 0.14922981 0.13763306 0.14036318\n",
            " 0.12513463 0.12455855 0.14226675 0.12726362 0.13684094 0.13703962\n",
            " 0.13815281 0.13969348 0.14139517 0.1431365  0.14486526 0.14655934\n",
            " 0.14821021 0.14981687 0.15138268 0.1529133 ]\n",
            "12 day output [[0.15441474]]\n",
            "13 day input [0.18407013 0.18146525 0.18169067 0.17873513 0.17715717 0.18827802\n",
            " 0.18249217 0.17051972 0.16320601 0.16363181 0.1636819  0.17092048\n",
            " 0.17204759 0.1636819  0.16588604 0.15769568 0.14875391 0.14444584\n",
            " 0.13918597 0.13720726 0.13259862 0.1323732  0.13119599 0.15902317\n",
            " 0.17016907 0.16974327 0.17282405 0.16546024 0.16418284 0.16235441\n",
            " 0.1702943  0.17392611 0.16350657 0.15479023 0.15539136 0.16518472\n",
            " 0.16458359 0.15539136 0.15143394 0.14396994 0.13332498 0.14001252\n",
            " 0.14529743 0.1459737  0.14116468 0.14958046 0.14875391 0.14108954\n",
            " 0.13139637 0.12673763 0.14053851 0.12944271 0.11994991 0.1096556\n",
            " 0.1208516  0.13212273 0.13470257 0.14311835 0.14662492 0.15524108\n",
            " 0.1587226  0.16839073 0.17001879 0.17222292 0.1806387  0.17765811\n",
            " 0.16974327 0.16899186 0.17933626 0.17087038 0.16278021 0.16355667\n",
            " 0.15842204 0.14755166 0.15233563 0.1591985  0.1463995  0.14584847\n",
            " 0.15168441 0.15125861 0.14922981 0.13763306 0.14036318 0.12513463\n",
            " 0.12455855 0.14226675 0.12726362 0.13684094 0.13703962 0.13815281\n",
            " 0.13969348 0.14139517 0.1431365  0.14486526 0.14655934 0.14821021\n",
            " 0.14981687 0.15138268 0.1529133  0.15441474]\n",
            "13 day output [[0.1558918]]\n",
            "14 day input [0.18146525 0.18169067 0.17873513 0.17715717 0.18827802 0.18249217\n",
            " 0.17051972 0.16320601 0.16363181 0.1636819  0.17092048 0.17204759\n",
            " 0.1636819  0.16588604 0.15769568 0.14875391 0.14444584 0.13918597\n",
            " 0.13720726 0.13259862 0.1323732  0.13119599 0.15902317 0.17016907\n",
            " 0.16974327 0.17282405 0.16546024 0.16418284 0.16235441 0.1702943\n",
            " 0.17392611 0.16350657 0.15479023 0.15539136 0.16518472 0.16458359\n",
            " 0.15539136 0.15143394 0.14396994 0.13332498 0.14001252 0.14529743\n",
            " 0.1459737  0.14116468 0.14958046 0.14875391 0.14108954 0.13139637\n",
            " 0.12673763 0.14053851 0.12944271 0.11994991 0.1096556  0.1208516\n",
            " 0.13212273 0.13470257 0.14311835 0.14662492 0.15524108 0.1587226\n",
            " 0.16839073 0.17001879 0.17222292 0.1806387  0.17765811 0.16974327\n",
            " 0.16899186 0.17933626 0.17087038 0.16278021 0.16355667 0.15842204\n",
            " 0.14755166 0.15233563 0.1591985  0.1463995  0.14584847 0.15168441\n",
            " 0.15125861 0.14922981 0.13763306 0.14036318 0.12513463 0.12455855\n",
            " 0.14226675 0.12726362 0.13684094 0.13703962 0.13815281 0.13969348\n",
            " 0.14139517 0.1431365  0.14486526 0.14655934 0.14821021 0.14981687\n",
            " 0.15138268 0.1529133  0.15441474 0.15589181]\n",
            "14 day output [[0.15734723]]\n",
            "15 day input [0.18169067 0.17873513 0.17715717 0.18827802 0.18249217 0.17051972\n",
            " 0.16320601 0.16363181 0.1636819  0.17092048 0.17204759 0.1636819\n",
            " 0.16588604 0.15769568 0.14875391 0.14444584 0.13918597 0.13720726\n",
            " 0.13259862 0.1323732  0.13119599 0.15902317 0.17016907 0.16974327\n",
            " 0.17282405 0.16546024 0.16418284 0.16235441 0.1702943  0.17392611\n",
            " 0.16350657 0.15479023 0.15539136 0.16518472 0.16458359 0.15539136\n",
            " 0.15143394 0.14396994 0.13332498 0.14001252 0.14529743 0.1459737\n",
            " 0.14116468 0.14958046 0.14875391 0.14108954 0.13139637 0.12673763\n",
            " 0.14053851 0.12944271 0.11994991 0.1096556  0.1208516  0.13212273\n",
            " 0.13470257 0.14311835 0.14662492 0.15524108 0.1587226  0.16839073\n",
            " 0.17001879 0.17222292 0.1806387  0.17765811 0.16974327 0.16899186\n",
            " 0.17933626 0.17087038 0.16278021 0.16355667 0.15842204 0.14755166\n",
            " 0.15233563 0.1591985  0.1463995  0.14584847 0.15168441 0.15125861\n",
            " 0.14922981 0.13763306 0.14036318 0.12513463 0.12455855 0.14226675\n",
            " 0.12726362 0.13684094 0.13703962 0.13815281 0.13969348 0.14139517\n",
            " 0.1431365  0.14486526 0.14655934 0.14821021 0.14981687 0.15138268\n",
            " 0.1529133  0.15441474 0.15589181 0.15734723]\n",
            "15 day output [[0.15878111]]\n",
            "16 day input [0.17873513 0.17715717 0.18827802 0.18249217 0.17051972 0.16320601\n",
            " 0.16363181 0.1636819  0.17092048 0.17204759 0.1636819  0.16588604\n",
            " 0.15769568 0.14875391 0.14444584 0.13918597 0.13720726 0.13259862\n",
            " 0.1323732  0.13119599 0.15902317 0.17016907 0.16974327 0.17282405\n",
            " 0.16546024 0.16418284 0.16235441 0.1702943  0.17392611 0.16350657\n",
            " 0.15479023 0.15539136 0.16518472 0.16458359 0.15539136 0.15143394\n",
            " 0.14396994 0.13332498 0.14001252 0.14529743 0.1459737  0.14116468\n",
            " 0.14958046 0.14875391 0.14108954 0.13139637 0.12673763 0.14053851\n",
            " 0.12944271 0.11994991 0.1096556  0.1208516  0.13212273 0.13470257\n",
            " 0.14311835 0.14662492 0.15524108 0.1587226  0.16839073 0.17001879\n",
            " 0.17222292 0.1806387  0.17765811 0.16974327 0.16899186 0.17933626\n",
            " 0.17087038 0.16278021 0.16355667 0.15842204 0.14755166 0.15233563\n",
            " 0.1591985  0.1463995  0.14584847 0.15168441 0.15125861 0.14922981\n",
            " 0.13763306 0.14036318 0.12513463 0.12455855 0.14226675 0.12726362\n",
            " 0.13684094 0.13703962 0.13815281 0.13969348 0.14139517 0.1431365\n",
            " 0.14486526 0.14655934 0.14821021 0.14981687 0.15138268 0.1529133\n",
            " 0.15441474 0.15589181 0.15734723 0.15878111]\n",
            "16 day output [[0.16019109]]\n",
            "17 day input [0.17715717 0.18827802 0.18249217 0.17051972 0.16320601 0.16363181\n",
            " 0.1636819  0.17092048 0.17204759 0.1636819  0.16588604 0.15769568\n",
            " 0.14875391 0.14444584 0.13918597 0.13720726 0.13259862 0.1323732\n",
            " 0.13119599 0.15902317 0.17016907 0.16974327 0.17282405 0.16546024\n",
            " 0.16418284 0.16235441 0.1702943  0.17392611 0.16350657 0.15479023\n",
            " 0.15539136 0.16518472 0.16458359 0.15539136 0.15143394 0.14396994\n",
            " 0.13332498 0.14001252 0.14529743 0.1459737  0.14116468 0.14958046\n",
            " 0.14875391 0.14108954 0.13139637 0.12673763 0.14053851 0.12944271\n",
            " 0.11994991 0.1096556  0.1208516  0.13212273 0.13470257 0.14311835\n",
            " 0.14662492 0.15524108 0.1587226  0.16839073 0.17001879 0.17222292\n",
            " 0.1806387  0.17765811 0.16974327 0.16899186 0.17933626 0.17087038\n",
            " 0.16278021 0.16355667 0.15842204 0.14755166 0.15233563 0.1591985\n",
            " 0.1463995  0.14584847 0.15168441 0.15125861 0.14922981 0.13763306\n",
            " 0.14036318 0.12513463 0.12455855 0.14226675 0.12726362 0.13684094\n",
            " 0.13703962 0.13815281 0.13969348 0.14139517 0.1431365  0.14486526\n",
            " 0.14655934 0.14821021 0.14981687 0.15138268 0.1529133  0.15441474\n",
            " 0.15589181 0.15734723 0.15878111 0.16019109]\n",
            "17 day output [[0.1615727]]\n",
            "18 day input [0.18827802 0.18249217 0.17051972 0.16320601 0.16363181 0.1636819\n",
            " 0.17092048 0.17204759 0.1636819  0.16588604 0.15769568 0.14875391\n",
            " 0.14444584 0.13918597 0.13720726 0.13259862 0.1323732  0.13119599\n",
            " 0.15902317 0.17016907 0.16974327 0.17282405 0.16546024 0.16418284\n",
            " 0.16235441 0.1702943  0.17392611 0.16350657 0.15479023 0.15539136\n",
            " 0.16518472 0.16458359 0.15539136 0.15143394 0.14396994 0.13332498\n",
            " 0.14001252 0.14529743 0.1459737  0.14116468 0.14958046 0.14875391\n",
            " 0.14108954 0.13139637 0.12673763 0.14053851 0.12944271 0.11994991\n",
            " 0.1096556  0.1208516  0.13212273 0.13470257 0.14311835 0.14662492\n",
            " 0.15524108 0.1587226  0.16839073 0.17001879 0.17222292 0.1806387\n",
            " 0.17765811 0.16974327 0.16899186 0.17933626 0.17087038 0.16278021\n",
            " 0.16355667 0.15842204 0.14755166 0.15233563 0.1591985  0.1463995\n",
            " 0.14584847 0.15168441 0.15125861 0.14922981 0.13763306 0.14036318\n",
            " 0.12513463 0.12455855 0.14226675 0.12726362 0.13684094 0.13703962\n",
            " 0.13815281 0.13969348 0.14139517 0.1431365  0.14486526 0.14655934\n",
            " 0.14821021 0.14981687 0.15138268 0.1529133  0.15441474 0.15589181\n",
            " 0.15734723 0.15878111 0.16019109 0.16157269]\n",
            "18 day output [[0.16292006]]\n",
            "19 day input [0.18249217 0.17051972 0.16320601 0.16363181 0.1636819  0.17092048\n",
            " 0.17204759 0.1636819  0.16588604 0.15769568 0.14875391 0.14444584\n",
            " 0.13918597 0.13720726 0.13259862 0.1323732  0.13119599 0.15902317\n",
            " 0.17016907 0.16974327 0.17282405 0.16546024 0.16418284 0.16235441\n",
            " 0.1702943  0.17392611 0.16350657 0.15479023 0.15539136 0.16518472\n",
            " 0.16458359 0.15539136 0.15143394 0.14396994 0.13332498 0.14001252\n",
            " 0.14529743 0.1459737  0.14116468 0.14958046 0.14875391 0.14108954\n",
            " 0.13139637 0.12673763 0.14053851 0.12944271 0.11994991 0.1096556\n",
            " 0.1208516  0.13212273 0.13470257 0.14311835 0.14662492 0.15524108\n",
            " 0.1587226  0.16839073 0.17001879 0.17222292 0.1806387  0.17765811\n",
            " 0.16974327 0.16899186 0.17933626 0.17087038 0.16278021 0.16355667\n",
            " 0.15842204 0.14755166 0.15233563 0.1591985  0.1463995  0.14584847\n",
            " 0.15168441 0.15125861 0.14922981 0.13763306 0.14036318 0.12513463\n",
            " 0.12455855 0.14226675 0.12726362 0.13684094 0.13703962 0.13815281\n",
            " 0.13969348 0.14139517 0.1431365  0.14486526 0.14655934 0.14821021\n",
            " 0.14981687 0.15138268 0.1529133  0.15441474 0.15589181 0.15734723\n",
            " 0.15878111 0.16019109 0.16157269 0.16292006]\n",
            "19 day output [[0.16422677]]\n",
            "20 day input [0.17051972 0.16320601 0.16363181 0.1636819  0.17092048 0.17204759\n",
            " 0.1636819  0.16588604 0.15769568 0.14875391 0.14444584 0.13918597\n",
            " 0.13720726 0.13259862 0.1323732  0.13119599 0.15902317 0.17016907\n",
            " 0.16974327 0.17282405 0.16546024 0.16418284 0.16235441 0.1702943\n",
            " 0.17392611 0.16350657 0.15479023 0.15539136 0.16518472 0.16458359\n",
            " 0.15539136 0.15143394 0.14396994 0.13332498 0.14001252 0.14529743\n",
            " 0.1459737  0.14116468 0.14958046 0.14875391 0.14108954 0.13139637\n",
            " 0.12673763 0.14053851 0.12944271 0.11994991 0.1096556  0.1208516\n",
            " 0.13212273 0.13470257 0.14311835 0.14662492 0.15524108 0.1587226\n",
            " 0.16839073 0.17001879 0.17222292 0.1806387  0.17765811 0.16974327\n",
            " 0.16899186 0.17933626 0.17087038 0.16278021 0.16355667 0.15842204\n",
            " 0.14755166 0.15233563 0.1591985  0.1463995  0.14584847 0.15168441\n",
            " 0.15125861 0.14922981 0.13763306 0.14036318 0.12513463 0.12455855\n",
            " 0.14226675 0.12726362 0.13684094 0.13703962 0.13815281 0.13969348\n",
            " 0.14139517 0.1431365  0.14486526 0.14655934 0.14821021 0.14981687\n",
            " 0.15138268 0.1529133  0.15441474 0.15589181 0.15734723 0.15878111\n",
            " 0.16019109 0.16157269 0.16292006 0.16422677]\n",
            "20 day output [[0.1654867]]\n",
            "21 day input [0.16320601 0.16363181 0.1636819  0.17092048 0.17204759 0.1636819\n",
            " 0.16588604 0.15769568 0.14875391 0.14444584 0.13918597 0.13720726\n",
            " 0.13259862 0.1323732  0.13119599 0.15902317 0.17016907 0.16974327\n",
            " 0.17282405 0.16546024 0.16418284 0.16235441 0.1702943  0.17392611\n",
            " 0.16350657 0.15479023 0.15539136 0.16518472 0.16458359 0.15539136\n",
            " 0.15143394 0.14396994 0.13332498 0.14001252 0.14529743 0.1459737\n",
            " 0.14116468 0.14958046 0.14875391 0.14108954 0.13139637 0.12673763\n",
            " 0.14053851 0.12944271 0.11994991 0.1096556  0.1208516  0.13212273\n",
            " 0.13470257 0.14311835 0.14662492 0.15524108 0.1587226  0.16839073\n",
            " 0.17001879 0.17222292 0.1806387  0.17765811 0.16974327 0.16899186\n",
            " 0.17933626 0.17087038 0.16278021 0.16355667 0.15842204 0.14755166\n",
            " 0.15233563 0.1591985  0.1463995  0.14584847 0.15168441 0.15125861\n",
            " 0.14922981 0.13763306 0.14036318 0.12513463 0.12455855 0.14226675\n",
            " 0.12726362 0.13684094 0.13703962 0.13815281 0.13969348 0.14139517\n",
            " 0.1431365  0.14486526 0.14655934 0.14821021 0.14981687 0.15138268\n",
            " 0.1529133  0.15441474 0.15589181 0.15734723 0.15878111 0.16019109\n",
            " 0.16157269 0.16292006 0.16422677 0.16548669]\n",
            "21 day output [[0.16669452]]\n",
            "22 day input [0.16363181 0.1636819  0.17092048 0.17204759 0.1636819  0.16588604\n",
            " 0.15769568 0.14875391 0.14444584 0.13918597 0.13720726 0.13259862\n",
            " 0.1323732  0.13119599 0.15902317 0.17016907 0.16974327 0.17282405\n",
            " 0.16546024 0.16418284 0.16235441 0.1702943  0.17392611 0.16350657\n",
            " 0.15479023 0.15539136 0.16518472 0.16458359 0.15539136 0.15143394\n",
            " 0.14396994 0.13332498 0.14001252 0.14529743 0.1459737  0.14116468\n",
            " 0.14958046 0.14875391 0.14108954 0.13139637 0.12673763 0.14053851\n",
            " 0.12944271 0.11994991 0.1096556  0.1208516  0.13212273 0.13470257\n",
            " 0.14311835 0.14662492 0.15524108 0.1587226  0.16839073 0.17001879\n",
            " 0.17222292 0.1806387  0.17765811 0.16974327 0.16899186 0.17933626\n",
            " 0.17087038 0.16278021 0.16355667 0.15842204 0.14755166 0.15233563\n",
            " 0.1591985  0.1463995  0.14584847 0.15168441 0.15125861 0.14922981\n",
            " 0.13763306 0.14036318 0.12513463 0.12455855 0.14226675 0.12726362\n",
            " 0.13684094 0.13703962 0.13815281 0.13969348 0.14139517 0.1431365\n",
            " 0.14486526 0.14655934 0.14821021 0.14981687 0.15138268 0.1529133\n",
            " 0.15441474 0.15589181 0.15734723 0.15878111 0.16019109 0.16157269\n",
            " 0.16292006 0.16422677 0.16548669 0.16669452]\n",
            "22 day output [[0.16784653]]\n",
            "23 day input [0.1636819  0.17092048 0.17204759 0.1636819  0.16588604 0.15769568\n",
            " 0.14875391 0.14444584 0.13918597 0.13720726 0.13259862 0.1323732\n",
            " 0.13119599 0.15902317 0.17016907 0.16974327 0.17282405 0.16546024\n",
            " 0.16418284 0.16235441 0.1702943  0.17392611 0.16350657 0.15479023\n",
            " 0.15539136 0.16518472 0.16458359 0.15539136 0.15143394 0.14396994\n",
            " 0.13332498 0.14001252 0.14529743 0.1459737  0.14116468 0.14958046\n",
            " 0.14875391 0.14108954 0.13139637 0.12673763 0.14053851 0.12944271\n",
            " 0.11994991 0.1096556  0.1208516  0.13212273 0.13470257 0.14311835\n",
            " 0.14662492 0.15524108 0.1587226  0.16839073 0.17001879 0.17222292\n",
            " 0.1806387  0.17765811 0.16974327 0.16899186 0.17933626 0.17087038\n",
            " 0.16278021 0.16355667 0.15842204 0.14755166 0.15233563 0.1591985\n",
            " 0.1463995  0.14584847 0.15168441 0.15125861 0.14922981 0.13763306\n",
            " 0.14036318 0.12513463 0.12455855 0.14226675 0.12726362 0.13684094\n",
            " 0.13703962 0.13815281 0.13969348 0.14139517 0.1431365  0.14486526\n",
            " 0.14655934 0.14821021 0.14981687 0.15138268 0.1529133  0.15441474\n",
            " 0.15589181 0.15734723 0.15878111 0.16019109 0.16157269 0.16292006\n",
            " 0.16422677 0.16548669 0.16669452 0.16784653]\n",
            "23 day output [[0.1689406]]\n",
            "24 day input [0.17092048 0.17204759 0.1636819  0.16588604 0.15769568 0.14875391\n",
            " 0.14444584 0.13918597 0.13720726 0.13259862 0.1323732  0.13119599\n",
            " 0.15902317 0.17016907 0.16974327 0.17282405 0.16546024 0.16418284\n",
            " 0.16235441 0.1702943  0.17392611 0.16350657 0.15479023 0.15539136\n",
            " 0.16518472 0.16458359 0.15539136 0.15143394 0.14396994 0.13332498\n",
            " 0.14001252 0.14529743 0.1459737  0.14116468 0.14958046 0.14875391\n",
            " 0.14108954 0.13139637 0.12673763 0.14053851 0.12944271 0.11994991\n",
            " 0.1096556  0.1208516  0.13212273 0.13470257 0.14311835 0.14662492\n",
            " 0.15524108 0.1587226  0.16839073 0.17001879 0.17222292 0.1806387\n",
            " 0.17765811 0.16974327 0.16899186 0.17933626 0.17087038 0.16278021\n",
            " 0.16355667 0.15842204 0.14755166 0.15233563 0.1591985  0.1463995\n",
            " 0.14584847 0.15168441 0.15125861 0.14922981 0.13763306 0.14036318\n",
            " 0.12513463 0.12455855 0.14226675 0.12726362 0.13684094 0.13703962\n",
            " 0.13815281 0.13969348 0.14139517 0.1431365  0.14486526 0.14655934\n",
            " 0.14821021 0.14981687 0.15138268 0.1529133  0.15441474 0.15589181\n",
            " 0.15734723 0.15878111 0.16019109 0.16157269 0.16292006 0.16422677\n",
            " 0.16548669 0.16669452 0.16784653 0.1689406 ]\n",
            "24 day output [[0.16997668]]\n",
            "25 day input [0.17204759 0.1636819  0.16588604 0.15769568 0.14875391 0.14444584\n",
            " 0.13918597 0.13720726 0.13259862 0.1323732  0.13119599 0.15902317\n",
            " 0.17016907 0.16974327 0.17282405 0.16546024 0.16418284 0.16235441\n",
            " 0.1702943  0.17392611 0.16350657 0.15479023 0.15539136 0.16518472\n",
            " 0.16458359 0.15539136 0.15143394 0.14396994 0.13332498 0.14001252\n",
            " 0.14529743 0.1459737  0.14116468 0.14958046 0.14875391 0.14108954\n",
            " 0.13139637 0.12673763 0.14053851 0.12944271 0.11994991 0.1096556\n",
            " 0.1208516  0.13212273 0.13470257 0.14311835 0.14662492 0.15524108\n",
            " 0.1587226  0.16839073 0.17001879 0.17222292 0.1806387  0.17765811\n",
            " 0.16974327 0.16899186 0.17933626 0.17087038 0.16278021 0.16355667\n",
            " 0.15842204 0.14755166 0.15233563 0.1591985  0.1463995  0.14584847\n",
            " 0.15168441 0.15125861 0.14922981 0.13763306 0.14036318 0.12513463\n",
            " 0.12455855 0.14226675 0.12726362 0.13684094 0.13703962 0.13815281\n",
            " 0.13969348 0.14139517 0.1431365  0.14486526 0.14655934 0.14821021\n",
            " 0.14981687 0.15138268 0.1529133  0.15441474 0.15589181 0.15734723\n",
            " 0.15878111 0.16019109 0.16157269 0.16292006 0.16422677 0.16548669\n",
            " 0.16669452 0.16784653 0.1689406  0.16997668]\n",
            "25 day output [[0.17095634]]\n",
            "26 day input [0.1636819  0.16588604 0.15769568 0.14875391 0.14444584 0.13918597\n",
            " 0.13720726 0.13259862 0.1323732  0.13119599 0.15902317 0.17016907\n",
            " 0.16974327 0.17282405 0.16546024 0.16418284 0.16235441 0.1702943\n",
            " 0.17392611 0.16350657 0.15479023 0.15539136 0.16518472 0.16458359\n",
            " 0.15539136 0.15143394 0.14396994 0.13332498 0.14001252 0.14529743\n",
            " 0.1459737  0.14116468 0.14958046 0.14875391 0.14108954 0.13139637\n",
            " 0.12673763 0.14053851 0.12944271 0.11994991 0.1096556  0.1208516\n",
            " 0.13212273 0.13470257 0.14311835 0.14662492 0.15524108 0.1587226\n",
            " 0.16839073 0.17001879 0.17222292 0.1806387  0.17765811 0.16974327\n",
            " 0.16899186 0.17933626 0.17087038 0.16278021 0.16355667 0.15842204\n",
            " 0.14755166 0.15233563 0.1591985  0.1463995  0.14584847 0.15168441\n",
            " 0.15125861 0.14922981 0.13763306 0.14036318 0.12513463 0.12455855\n",
            " 0.14226675 0.12726362 0.13684094 0.13703962 0.13815281 0.13969348\n",
            " 0.14139517 0.1431365  0.14486526 0.14655934 0.14821021 0.14981687\n",
            " 0.15138268 0.1529133  0.15441474 0.15589181 0.15734723 0.15878111\n",
            " 0.16019109 0.16157269 0.16292006 0.16422677 0.16548669 0.16669452\n",
            " 0.16784653 0.1689406  0.16997668 0.17095634]\n",
            "26 day output [[0.17188278]]\n",
            "27 day input [0.16588604 0.15769568 0.14875391 0.14444584 0.13918597 0.13720726\n",
            " 0.13259862 0.1323732  0.13119599 0.15902317 0.17016907 0.16974327\n",
            " 0.17282405 0.16546024 0.16418284 0.16235441 0.1702943  0.17392611\n",
            " 0.16350657 0.15479023 0.15539136 0.16518472 0.16458359 0.15539136\n",
            " 0.15143394 0.14396994 0.13332498 0.14001252 0.14529743 0.1459737\n",
            " 0.14116468 0.14958046 0.14875391 0.14108954 0.13139637 0.12673763\n",
            " 0.14053851 0.12944271 0.11994991 0.1096556  0.1208516  0.13212273\n",
            " 0.13470257 0.14311835 0.14662492 0.15524108 0.1587226  0.16839073\n",
            " 0.17001879 0.17222292 0.1806387  0.17765811 0.16974327 0.16899186\n",
            " 0.17933626 0.17087038 0.16278021 0.16355667 0.15842204 0.14755166\n",
            " 0.15233563 0.1591985  0.1463995  0.14584847 0.15168441 0.15125861\n",
            " 0.14922981 0.13763306 0.14036318 0.12513463 0.12455855 0.14226675\n",
            " 0.12726362 0.13684094 0.13703962 0.13815281 0.13969348 0.14139517\n",
            " 0.1431365  0.14486526 0.14655934 0.14821021 0.14981687 0.15138268\n",
            " 0.1529133  0.15441474 0.15589181 0.15734723 0.15878111 0.16019109\n",
            " 0.16157269 0.16292006 0.16422677 0.16548669 0.16669452 0.16784653\n",
            " 0.1689406  0.16997668 0.17095634 0.17188278]\n",
            "27 day output [[0.17276046]]\n",
            "28 day input [0.15769568 0.14875391 0.14444584 0.13918597 0.13720726 0.13259862\n",
            " 0.1323732  0.13119599 0.15902317 0.17016907 0.16974327 0.17282405\n",
            " 0.16546024 0.16418284 0.16235441 0.1702943  0.17392611 0.16350657\n",
            " 0.15479023 0.15539136 0.16518472 0.16458359 0.15539136 0.15143394\n",
            " 0.14396994 0.13332498 0.14001252 0.14529743 0.1459737  0.14116468\n",
            " 0.14958046 0.14875391 0.14108954 0.13139637 0.12673763 0.14053851\n",
            " 0.12944271 0.11994991 0.1096556  0.1208516  0.13212273 0.13470257\n",
            " 0.14311835 0.14662492 0.15524108 0.1587226  0.16839073 0.17001879\n",
            " 0.17222292 0.1806387  0.17765811 0.16974327 0.16899186 0.17933626\n",
            " 0.17087038 0.16278021 0.16355667 0.15842204 0.14755166 0.15233563\n",
            " 0.1591985  0.1463995  0.14584847 0.15168441 0.15125861 0.14922981\n",
            " 0.13763306 0.14036318 0.12513463 0.12455855 0.14226675 0.12726362\n",
            " 0.13684094 0.13703962 0.13815281 0.13969348 0.14139517 0.1431365\n",
            " 0.14486526 0.14655934 0.14821021 0.14981687 0.15138268 0.1529133\n",
            " 0.15441474 0.15589181 0.15734723 0.15878111 0.16019109 0.16157269\n",
            " 0.16292006 0.16422677 0.16548669 0.16669452 0.16784653 0.1689406\n",
            " 0.16997668 0.17095634 0.17188278 0.17276046]\n",
            "28 day output [[0.17359439]]\n",
            "29 day input [0.14875391 0.14444584 0.13918597 0.13720726 0.13259862 0.1323732\n",
            " 0.13119599 0.15902317 0.17016907 0.16974327 0.17282405 0.16546024\n",
            " 0.16418284 0.16235441 0.1702943  0.17392611 0.16350657 0.15479023\n",
            " 0.15539136 0.16518472 0.16458359 0.15539136 0.15143394 0.14396994\n",
            " 0.13332498 0.14001252 0.14529743 0.1459737  0.14116468 0.14958046\n",
            " 0.14875391 0.14108954 0.13139637 0.12673763 0.14053851 0.12944271\n",
            " 0.11994991 0.1096556  0.1208516  0.13212273 0.13470257 0.14311835\n",
            " 0.14662492 0.15524108 0.1587226  0.16839073 0.17001879 0.17222292\n",
            " 0.1806387  0.17765811 0.16974327 0.16899186 0.17933626 0.17087038\n",
            " 0.16278021 0.16355667 0.15842204 0.14755166 0.15233563 0.1591985\n",
            " 0.1463995  0.14584847 0.15168441 0.15125861 0.14922981 0.13763306\n",
            " 0.14036318 0.12513463 0.12455855 0.14226675 0.12726362 0.13684094\n",
            " 0.13703962 0.13815281 0.13969348 0.14139517 0.1431365  0.14486526\n",
            " 0.14655934 0.14821021 0.14981687 0.15138268 0.1529133  0.15441474\n",
            " 0.15589181 0.15734723 0.15878111 0.16019109 0.16157269 0.16292006\n",
            " 0.16422677 0.16548669 0.16669452 0.16784653 0.1689406  0.16997668\n",
            " 0.17095634 0.17188278 0.17276046 0.17359439]\n",
            "29 day output [[0.17439005]]\n",
            "[[0.13684093952178955], [0.13703961670398712], [0.1381528079509735], [0.139693483710289], [0.14139516651630402], [0.14313650131225586], [0.1448652595281601], [0.14655934274196625], [0.14821021258831024], [0.1498168706893921], [0.1513826847076416], [0.15291330218315125], [0.15441474318504333], [0.1558918058872223], [0.15734723210334778], [0.15878111124038696], [0.16019108891487122], [0.16157269477844238], [0.1629200577735901], [0.16422677040100098], [0.16548669338226318], [0.1666945219039917], [0.16784653067588806], [0.16894060373306274], [0.16997668147087097], [0.1709563434123993], [0.1718827784061432], [0.17276045680046082], [0.1735943853855133], [0.17439004778862]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "n19BBDqKd25s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}